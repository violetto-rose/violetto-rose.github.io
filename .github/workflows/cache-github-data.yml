name: Cache GitHub Data

on:
  schedule:
    # Run every day
    - cron: '0 0 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches: ['main']
    paths:
      - '.github/workflows/cache-github-data.yml'

jobs:
  cache-github-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Fetch GitHub Contributions
        id: fetch-contributions
        env:
          GH_TOKEN: ${{ secrets.GH_API_TOKEN }}
          GITHUB_USERNAME: 'violetto-rose'
        run: |
          node -e "
          const https = require('https');
          const fs = require('fs');

          function fetchWithAuth(url, token) {
            return new Promise((resolve, reject) => {
              const options = {
                headers: {
                  'Authorization': \`Bearer \${token}\`,
                  'Accept': 'application/vnd.github+json',
                  'User-Agent': 'GitHub-Pages-Cache'
                }
              };

              https.get(url, options, (res) => {
                let data = '';
                res.on('data', chunk => data += chunk);
                res.on('end', () => {
                  if (res.statusCode === 200) {
                    resolve(JSON.parse(data));
                  } else {
                    reject(new Error(\`API error: \${res.statusCode}\`));
                  }
                });
              }).on('error', reject);
            });
          }

          function parseLinkHeader(linkHeader) {
            if (!linkHeader) return null;
            const links = linkHeader.split(',');
            for (const link of links) {
              const parts = link.split(';');
              const url = parts[0].trim().replace(/^<|>$/g, '');
              const rel = parts[1]?.trim().toLowerCase();
              if (rel && rel.includes('next')) {
                return url;
              }
            }
            return null;
          }

          async function fetchAllPages(url, token, maxPages = 10) {
            const allItems = [];
            let currentUrl = url;
            let pageCount = 0;

            while (currentUrl && pageCount < maxPages) {
              const response = await new Promise((resolve, reject) => {
                const options = {
                  headers: {
                    'Authorization': \`Bearer \${token}\`,
                    'Accept': 'application/vnd.github+json',
                    'User-Agent': 'GitHub-Pages-Cache'
                  }
                };

                https.get(currentUrl, options, (res) => {
                  let data = '';
                  res.on('data', chunk => data += chunk);
                  res.on('end', () => {
                    resolve({ statusCode: res.statusCode, headers: res.headers, data: data });
                  });
                }).on('error', reject);
              });

              if (response.statusCode !== 200) {
                break;
              }

              const items = JSON.parse(response.data);
              if (!Array.isArray(items)) break;

              allItems.push(...items);

              const linkHeader = response.headers.link;
              currentUrl = parseLinkHeader(linkHeader);
              pageCount++;

              if (items.length < 100) break;
            }

            return allItems;
          }

          async function fetchContributions() {
            try {
              const token = process.env.GH_TOKEN;
              const username = process.env.GITHUB_USERNAME;

              if (!token) {
                console.log('No token provided, skipping contributions fetch');
                process.exit(0);
              }

              // Fetch repositories
              const reposUrl = 'https://api.github.com/user/repos?per_page=100&sort=updated&affiliation=owner';
              const repos = await fetchAllPages(reposUrl, token, 10);
              console.log(\`Found \${repos.length} repositories\`);

              // Calculate date range: from today going back 365 days
              const today = new Date();
              today.setHours(23, 59, 59, 999); // End of today
              const oneYearAgo = new Date(today);
              oneYearAgo.setDate(oneYearAgo.getDate() - 365);
              oneYearAgo.setHours(0, 0, 0, 0); // Start of that day

              const allCommits = [];

              const maxRepos = Math.min(repos.length, 50);
              for (let i = 0; i < maxRepos; i++) {
                const repo = repos[i];
                const [owner, repoName] = repo.full_name.split('/');
                const sinceISO = oneYearAgo.toISOString();
                const commitsUrl = \`https://api.github.com/repos/\${owner}/\${repoName}/commits?since=\${sinceISO}&author=\${username}&per_page=100\`;

                const commits = await fetchAllPages(commitsUrl, token, 10);
                allCommits.push(...commits);
                console.log(\`Fetched \${commits.length} commits from \${repo.full_name}\`);
              }

              // Process into contribution map (last 365 days from today)
              const contributionMap = {};
              allCommits.forEach(commit => {
                if (commit.commit && commit.commit.author && commit.commit.author.date) {
                  const date = new Date(commit.commit.author.date);
                  // Include commits from oneYearAgo to today (inclusive)
                  if (date >= oneYearAgo && date <= today) {
                    const dateKey = date.toISOString().split('T')[0];
                    contributionMap[dateKey] = (contributionMap[dateKey] || 0) + 1;
                  }
                }
              });

              const contributions = Object.entries(contributionMap).map(([dateStr, value]) => ({
                date: dateStr + 'T00:00:00',
                value: value
              }));

              fs.writeFileSync('public/data/github-contributions.json', JSON.stringify(contributions, null, 2));
              console.log(\`Processed \${contributions.length} days with contributions\`);
            } catch (error) {
              console.error('Error fetching contributions:', error.message);
              process.exit(1);
            }
          }

          fetchContributions();
          "

      - name: Create data directory if it doesn't exist
        run: |
          mkdir -p public/data

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add public/data/github-contributions.json
          git diff --staged --quiet || (git commit -m "Update cached GitHub data" && git push)
